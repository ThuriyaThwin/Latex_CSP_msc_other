\section{Benchmarking}
% [todo] - review this section
% [todo] - explain the conditions of the tests, compare to conditions in deGivry14
In order to determine the efficiency of the algorithm, and determine what problem paradigm the algorithm is most usefully applied to, extensive benchmark testing will be performed.
The algorithm was tested against (part of) the large problem set used by \textcite{deGivry14}, which includes problems from the \gls{mrf}, \gls{wpms}, \gls{cfn}, Max-\gls{csp}, \gls{cp} and \gls{cvpr} domains.
All problems in the set are available in the \textsc{wcsp} file format.
Exact data (elapsed time and obtained solution for every solver, as well as proven optima and upper bounds for every problem) for these data sets have been obtained directly from \citeauthor{deGivry14}.

This section will describe the method used to benchmark the algorithm, including the calculation of presented data.
It will also briefly present the problems used in the benchmark, to provide background that may explain the performance characteristics of the algorithm, as well as short introductions to other solvers with which the in-the-middle algorithm will be compared.

\subsection{Benchmarking method}
All problem instances were limited in runtime by the upper time limit \(t_{\text{max}} = \SI{1200}{\second}\), and the benchmarks were run on an Intel~Core~i5 processor at \SI{2.3}{\giga\hertz}, with \SI{8}{\gibi\byte} RAM.
This is comparable to the conditions of the benchmark performed by \textcite{deGivry14}, and should ensure that the comparisons are valid.

Since the algorithm, when used with the corresponding heuristic, is an inexact algorithm (while the solvers benchmarked by \textcite{deGivry14} are all exact solvers) the quality of the solution must be compared in addition to the elapsed time per problem.
While the time may be compared as-is (given the comparable hardware conditions), the found solution will have to be compared relative to the proven optimum for each problem.

\label{pg:bench-method}
The relative deviation of the obtained solution may be calculated as \((f - \bar{f})/(\mathrm{UB}-\mathrm{LB})\), where \(f\) is the solution found by the algorithm, \(\bar{f}\) is the proven optimum and \(\mathrm{UB}, \mathrm{LB}\) is the trivial upper and lower bound of the problem (the upper bound is specified in the \textsc{wcsp} format, and the lower bound is trivially the lowest cost among all constraints).
When \(\bar{f}\) is unknown, the lower bound is used instead.

\subsection{Problem sets}
The problem sets obtained from \textcite{deGivry14} belong to a number of different domains and represent different types of problems from industry, academia and random generation.
This section will briefly review each problem set used in the benchmark, and review both problem source, interpretation and size.
% [review] - wcsp same as cfn, make this clear? < should be made clear when presenting cfn/wcsp
All of these problems are directly representable as \gls{wcsp} problems, and hence as max-sum optimization problems, and \textcite{deGivry14} provide details on the translation from each field to the \gls{wcsp} formulation used in this benchmark.

Several sets from the benchmark performed by \textcite{deGivry14} have been omitted from this benchmark.
This is because the in-the-middle algorithm wasn't able to solve any instances in the set (due to time or memory constraints), making them uninteresting in the sense that the algorithm isn't a feasible alternative for those problems. 
The omitted problem sets are mostly from the \gls{cp} and \gls{wpms} categories (where only two resp. one problem(s) were kept), but the \emph{Chinese Characters}, \emph{Color Segmentation}, \emph{Matching Stereo} and \emph{Photo Montage} sets from \gls{cvpr} are also omitted from the benchmark.
% [todo] - review briefly the different fields?
% [todo] - mention mean/median number of hard/soft constraints in each problem set? use c program to find out! 

\subsubsection{Constraint Function Network (CFN)}
This category contains six problem sets, all from the CFLib collection mentioned by \textcite[\pno~3]{deGivry14}.
Most of them are real-world problems or generated to approximate such problems, and all of them are readily available in the WCSP file format mentioned earlier.

\begin{description}
	\item[Auction]
		The combinatorial auction problem has been previously used by \textcites{Larrosa08}{Sandholm99}.
		In summary, the problem allows bidders to bid for indivisible subsets of goods, and the optimization problem is to maximize the revenue of the bid-taker.
		The problems are generated, but inspired by real-world scenarios.
		All variables are binary (the original problem is a binary Max-SAT problem), and the problems contain up to \num{246} variables and \num{12000} constraints.

		The problem set includes \emph{scheduling} and \emph{path} distribution problems, but omits the \emph{regions} distribution mentioned by \textcite[\pno~228]{Larrosa08}.

	\item[CELAR]
		As detailed by \textcite{Cabon99} \parencite[and to some extent][\pno~315\psq]{Meseguer06}, this problem set concerns radio frequency assignment, \emph{i.e.} the problem of providing communication channels from limited resources while minimizing interference in the network.
		The problems where initially introduced in 1993 by \emph{Centre d’Electronique de l’Armement}, and are based on real-world data.

		The CELAR problems are fairly large, with variable domains ranging up to \num{44}, with up to \num{458} variables and \num{2400} constraints.
		Problems included in the benchmark are mainly the CELAR sub-instances \parencite[\pno~85]{Cabon99} and some GRAPH instances.

	\item[Pedigree]
		This category contains problems relating to the Mendelian error correction on complex pedigree \parencites{Sanchez08}[\pno~317\psq]{Meseguer06}, which is a real-world \gls{wcsp} problem.
		The problem may be described as surveying a pedigree (similar to a family tree), detecting individuals that are erroneous in the sense that they do not conform to the Mendelian laws of inheritance.
		Specifically, the problem formulation is to find the minimum number of errors needed to explain erroneous data.

		The problems are very large, with the number of variables reaching \num{10000} and almost \num{20000} constraints, with variable domains around \num{25}.

	\item[Protein Design]
		Computational Protein Design problems concern the identification of proteins performing given tasks. The actual problem statement is the optimization of a complex energy function over amino acid sequences, and it is described in length by \textcite{Allouche12}.

		The problems may be expressed by \gls{cfn} or integer \gls{lp} models — only the \gls{cfn} formulations are used in this benchmark. The problems contain few (roughly \num{20}) variables with very large domains (up to \num{200}), and around \num{170} constraints.

	\item[SPOT5]
		The SPOT5 problems are in essence planning problems, taken from real-world planning of earth optical observation satellites.
		Given a number of images to be taken during one day using one of three instruments, an associated importance and a set of imperative constraints (transition times, data flow limitations, on-board recording capacity \emph{etc.}), the problem is to find a feasible subset of images that maximize the sum of the associated weights \parencite{Bensana99}.

		The problems are large, with roughly \num{1000} variables and \num{22000} constraints, but the variables are all 4-ary.

	\item[Warehouse]
		Originally presented by \textcite{Kratica01}, the uncapacitated warehouse location instances are randomly generated instances of the facility location problem. In essence, the problem concerns the optimal placement of facilities (in this case warehouses) while minimizing transport costs. These instances were previously used by \textcite{deGivry05} in their evaluation of existential arc consistency for \glspl{csp}.

		These problem instances are very large. The variable domain reaches \num{300} for some problems, with \num{1100} variables and \num{101100} constraint functions.

\end{description}

\subsubsection{Constraint Programming (CP)}
Two problems (one real-world problem and one academic) from this category have been included in this benchmark.
All problems in these sets come from the MiniZinc Challenge\footnote{\url{http://www.minizinc.org/}} \parencite[\pno~5]{deGivry14}, and represent specific problems (representable as \gls{wcsp} instances) defined through Constraint Programming languages.
% [review] - page number above will have to change
Note that \gls{cp} problems are not generally representable as \glspl{wcsp}, which makes this category less interesting in the context of \gls{wcsp} or max-sum algorithms.

\begin{description}
%	\item[A Maze]
%	\item[Fast Food]
%	\item[Golomb]
	\item[On Call Rostering]
		This problem is a planning problem in which staff members are assigned to days in a rostering period.
		Requirements on staff (both forced rostering and staff being unavailable) affect the schedule, and work load should be even over the rostering period.
		Additionally, staff members are not allowed to be on call more than two days in a row, and prefer not to be on call for two consecutive days.
		Other, similar constraints may also be present.

		Problems in this set are generally fairly large in terms of domain size (up to \num{90}), but only contain up to \num{2200} variables and \num{4500} constraints, which is small compared to other sets.
	
	\item[Parity Learning]
		The Parity Learning set contains instances of an optimization variant of the Minimal Disagreement Parity problem \parencite{Crawford94}.
		A set of input/output samples of a Boolean function is given, where the function outputs the parity of an unkown subset of the input variables.
		A stated number of the input/output samples are incorrect with respect to the given function, and the goal of the parity learning problem is to find a subset of the input variables that minimizes the number of errors.

		In terms of problem size, instances of this set are fairly small. The number of variables is below \num{760}, and the number of constraints at most \num{1440}. The variable domain sizes are below \num{20}.
%	\item[VRP]
\end{description}

\subsubsection{Computer Vision and Pattern Recognition (CVPR)}
In this category there are nine problem sets containing \gls{mrf} instances from the OpenGM2 benchmark \parencite{Kappes13}.
The problems have been collected from various sources \parencite[\pno~1330]{Kappes13}, but all concern various computer vision tasks performed on real-world images.

The size of these problems vary, with \numrange{20}{500000} variables, \numrange{210}{2000000} constraints and variable domains reaching \num{20} for some sets.

% [review] - omitted: ChineseChars, ColorSeg, MatchingStereo, PhotoMontage

% [review] - explain every set?

\subsubsection{Max-CSP}
The seven max-\gls{csp} sets are restated binary \gls{csp} instances such that the optimal solution of each instance is the minimal number of unsatisfiable constraints in the original \gls{csp} problem.
The instances are from the 2008 max-\gls{csp} competition\multfootnote{\url{http://www.cril.univ-artois.fr/~lecoutre/benchmarks.html};\url{http://www.cril.univ-artois.fr/CPAI08/}}.

% [todo] - describe problems!

% descriptions from http://www.cril.univ-artois.fr/~lecoutre/benchmarks.html

\begin{description}
	\item[Black Hole]
% The Black Hole problem is the task of moving all cards of 17 fans of 3 cards each to the center pile, the Black hole, which initially only contains the Ace of Spades. Three series of instances (which correspond to a simplification of the original problem) have been generated by Radoslaw Szymanek for the 2005 CSP Solver Competition. They are denoted by blackHole-4-n with n in {4,7,13}. (Academic problem)
% I. Gent, C. Jefferson, I. Lynce, I. Miguel, P. Nightingale, B. Smith, and A. Tarim. Search in the patience game ’black hole’. Technical report, Cork Constraint Com- putation Centre, 2005.
		\parencite{Gent07}
	\item[Coloring]
% The graph coloring problem can be stated as follows: given a graph G=(V,E), the objective is to find the minimum number of colors k such that there exists a mapping r from V to 1..k with r(i) <> r(j) for every edge (i,j) of G. The decision problem associated with this optimization problem involves determining if the graph can be colored when using a given number of colors k. All CSP instances given here have been built from resources that can be found here . We would like to thank very much Mickael Trick for kindly authorizing us to exploit the resources he has collected. Concerning the instances, some interesting results can be found in [Benhamou and Saidi, Local Symmetry Breaking During Search in CSPs, CP'07].
		DIMACS and \parencite{Benhamou07}
	\item[Composed]
% Here are 9 classes of 10 random CSP instances such that each generated instance is composed of a main (under-constrained, here) fragment and some auxiliary fragments, each of which being grafted to the main one by introducing some binary constraints. Such classes have been introduced in: [Lecoutre-Boussemart-Hemery, Backjump-based techniques versus conflict-directed heuristics, ICTAI'04]. Related instances have been experimented in [Jussien-Debruyne-Boizumault, Maintaining arc consistency within dynamic backtracking, CP'00] (Random problem)
		\parencite{Lecoutre04}
	\item[EHI]
% A 3-SAT instance is a SAT instance such that each clause contains exactly 3 literals. Two series of 3-SAT unsatisfiable instances have been converted into CSP instances using the dual method as described in [Bacchus, Extending forward checking, CP'00]. See [Lecoutre-Boussemart-Hemery, Backjump-based techniques versus conflict-directed heuristics, ICTAI'04]. These series are denoted by ehi-85 and ehi-90. (Random problem)
		\parencite{Lecoutre04}
	\item[Geometric]
% The Geometric problem has been proposed by Rick Wallace. The geometric instances are a kind of random instances generated as follows. Instead of a density parameter, a "distance" parameter, dst, is used such that dst <= sqrt(2). For each variable, two coordinates are chosen at random so the associated point lies in the unit square. Then for each variable pair, (x,y), if the distance between their associated points is less than or equal to dst, the arc (x,y) is added to the constraint graph. Constraint relations are created in the same way as they are for homogeneous random CSP instances. Each instance is prefixed by geom. (Random problem)
	\item[Langford]
% The (generalized version of the) problem is to arrange k sets of numbers ranging from 1 to n, so that each appearance of the number m is m numbers on from the last. See prob024 at CSPLib. Each instance is denoted by langford-k-n. (Academic problem)
	\item[QCP]
% The Quasi-group Completion problem (QCP) is the task of determining whether the remaining entries of the partial Latin square can be filled in such a way that we obtain a complete Latin square, ie. a full multiplication table of a quasi-group. The Quasi-group With Holes problem (QWH) is a variant of the QCP as instances are generated in such a way that they are guaranteed to be satisfiable. These 8 series of instances have been generated by Radoslaw Szymanek for the 2005 CSP Solver Competition. (Academic problem)
% C.P. Gomez and D. Shmoys. Completing quasigroups or latin squares: a structured graph coloring problem. In Proceedings of Computational Symposium on Graph Coloring and Generalization, 2002.
		\parencite{Gomes02}
		% [review] - Gomes02 is an incomplete reference
\end{description}

\subsubsection{Markov Random Fields (MRF)}
This category consists of seven sets, where the task is to estimate \gls{map} probabilities on \gls{mrf}. The sets represent different underlying problems such as image alignment, genetic linkage analysis, protein folding and other probabilistic problems.

All of these problems, except those in the \emph{Linkage} set (which was used in the UAI08 probabilistic inference evaluation and later by \textcite{Favier11} in their work on pairwise decomposition), are from the 2011 Probabilistic Inference Challenge\footnote{\url{http://www.cs.huji.ac.il/project/PASCAL/}}.
The problems were translated into their \gls{wcsp} equivalent using a \(-\log*{}\) transformation \parencite[\pno~4]{deGivry14}.
% [review] - page number above will have to change

Most problems are modest in size, with \numrange{60}{2000} variables and \numrange{1000}{10000} constraints and variable domains below \num{30}. 
Some problems have variable domains approaching \num{500}, and some have up to \num{6400} variables and \num{20000} constraints.
Notably, the \emph{Segmentation} set contains both binary and 21-ary formulations of each problem.

% [review] - describe every set?

\subsubsection{Weighted Partial Max-SAT (WPMS)}
From the field of \gls{wpms}, only one problem set was kept.
Problems in this fiels contain a very large number of (binary, for obvious reasons) variables and cost functions with very large arity --- in fact, this is the only field in which cost function arity exceeds \num{5} (most other sets have cost functions of two variables only).
The only kept problem set, \emph{Max-Clique}, has a cost function arity of \num{2}.
Discarded sets were omitted due to memory concerns, likely caused by inefficient representation of the cost functions.
The instances were used in the eigth Max-SAT Evaluation\footnote{\url{http://maxsat.ia.udl.cat/13/benchmarks/}},

\begin{description}
%	\item[Haplotyping]
	\item[Max-Clique]
		The Max-Clique problem, which may be restated as a max-SAT problem \parencite{Heras08}, is the well-known problem of finding the largest \emph{clique} (complete subgraph) of a graph.
		It may be regarded as an academic problem, but has many applications to real-world problems and has seen extensive study when it comes to tailored algorithms for the original formulation.
		The original instances are from the second DIMACS challenge \parencite{Johnson96}, and have been previously used by \emph{e.g.} \textcite{Östergård02} for benchmarking max-clique algorithms.

		When translated into their max-SAT equivalent, max-clique instances become very large. While the number of variables is fairly low (below \num{3400}), the number of constraints is very large (approaching \num{380000}).
%	\item[MIPLib]
%	\item[Packup Weighted]
%	\item[Planning With Preferences]
%	\item[Timetabling]
%	\item[Upgradeability]
\end{description}

\subsection{Solvers}
% [todo] - review briefly the method each solver uses, with references to original articles if possible

%\subsubsection{MPLP2}

\subsubsection{Toulbar2}
Description in \parencite{Allouche10}, first mentioned by \textcite{deGivry05} and later improved (see deGivry14 for more refs) and also mentioned in \parencite{Sanchez08}

\subsubsection{CPLEX}

\subsubsection{MaxHS}
Introduced by \textcite{Davies11} and improved by \parencite{Davies13}
