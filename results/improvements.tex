% [todo] - move table/figures around
\section{Extensions and improvements}
Two variants of the algorithm have been discussed earlier in the thesis, with different purpose and functionality.
Benchmark data was produced for these variants as well, but on a limited subset of the problems, chosen specifically to test the variants and their intended purpose.
Results for both variants will be reviewed in in order to determine if they have the desired effect, and if their function is satisfactory with respect to the drawbacks they introduce.
Results will be presented by comparison with the original benchmark only, without the solvers benchmarked by \textcite{deGivry14}.

% [todo] - explaining why sets were chosen
% [todo] - analyzing the results
% [todo] - were results as expected?
% [todo] - is a given improvement useful?

\subsection{The \enquote{push} operation}
The purpose of the \enquote{push} operation is to decrease the optimality gap of the approximative algorithm once a feasible solution has been found.
Six problem sets from \cref{tab:comparative-results} were therefore chosen for this benchmark, all with comparatively bad solutions (solution differences close to or above \SI{1}{\percent}) but competitive runtimes.
The expectation was to obtain better solutions while maintaining good runtimes.

\Cref{tab:push-results} shows the results of benchmarking the \enquote{push} operation on the selected problems.
Surprisingly, the optimality gap did not improve for a majority of the problems.
In fact, for some sets the optimality gap was increased, and the runtime of the algorithm improved instead (which given the already competitive runtime of the standard algorithm is an unwanted result).
In fact, the only problem set for which the excpected result was obained is the \gls{cfn} \emph{Pedigree} set.

The reason for this is likely that the algorithm, in trials after the \enquote{push} operation has been applied, is more conservative than the original algorithm in that the maximum \(\kappa\) value will be lower. This means more trials fail to force an integer solution, reducing the number of trials and as a consequence reducing the runtime as well as increasing the optimality gap.
A more correct implementation would take into consideration the reduction of \(\kappa\) caused by the push operation when calculating the maximum \(\kappa\) value of subsequent trials.
% [review] - maybe not true
% [fix] - introduce this fix and re-run trials?

Due to these results, the \enquote{push} operation is not as interesting when applied to the max-sum algorithm as it is in the original \gls{lp} formulation.
% [todo] - analyze why it works on the CFN/Pedigree problem!

% Interesting cactus plots: Mainly MaxCSP/BlackHole when compared to standard

\begin{table}
	\centering
	% Updated 2014-05-24
	\caption{
		Optimality gap and runtime using the \enquote{push} operation.
		For several chosen problem sets, the \enquote{push} variant runtime is compared to the results obtained by the standard algorithm (see \cref{tab:comparative-results}).
	}
	% [todo] - double-check all table data!
	\label{tab:push-results}
	\begin{figcenter}
	\begin{tabular}{xySSS[round-mode=places,round-precision=3,scientific-notation=fixed,fixed-exponent=0]
				     S[round-mode=places,round-precision=3,scientific-notation=fixed,fixed-exponent=0]
				     S[round-mode=places,round-precision=2,scientific-notation=fixed,fixed-exponent=0]
				     S[round-mode=places,round-precision=2,scientific-notation=fixed,fixed-exponent=0]}
		\toprule
			{} & {} & \multicolumn{2}{c}{\(\#\) solved} & \multicolumn{2}{c}{Gap (\si{\percent})} & \multicolumn{2}{c}{Mean time (\si{\second})} \\
			\cmidrule(rl){3-4} \cmidrule(rl){5-6} \cmidrule(rl){7-8}
			{\normalsize Category} & {\normalsize Set} & {Std.} & {\enquote{Push}} & {Std.} & {\enquote{Push}} & {Std.} & {\enquote{Push}} \\
		\midrule
\acrshort{cfn}	&	Pedigree	&	10	&	10	&	1.804874e-00	&	1.51249400	&	2.3750	&	5.6070 \\
\acrshort{cvpr}	&	GeomSurf	&	600	&	600	&	2.091307e-00	&	2.09130700	&	0.0460	&	0.0425 \\
				&	SceneDecomp	&	715	&	715	&	7.545481e+01	&	75.4547890	&	0.0210	&	0.0170 \\
Max-\acrshort{csp}	&	BlackHole	&	37	&	37	&	9.009009e-01	&	1.08108100	&	58.8900	&	31.3310 \\
				&	Langford	&	4	&	4	&	1.311265e-00	&	1.55417600	&	70.7775	&	56.2925 \\
				&	QCP	&	60	&	60	&	1.292034e-00	&	1.30359500	&	43.2575	&	38.0705 \\
\acrshort{mrf}	&	ObjectDetection	&	37	&	37	&	6.465565e-00	&	6.46556500	&	279.8620	&	167.0170 \\
		\bottomrule
	\end{tabular}
	\end{figcenter}
\end{table}


\subsection{The greedy DP update}
The greedy DP update, obtained by fixing \(\alpha=1\) of the fractional DP update, should theoretically improve convergence at the expense of the optimality guarantee.
Here, a large number of problems from \cref{tab:comparative-results} were selected, all exhibiting low optimality gaps and a reasonable but uncompetitive runtime.
The expectation was to decrease runtime at the expense of solution quality.
Additionally, some sets with zero optimality gap and competitive runtime were included to observe the effects of this variant on already well-performing problem sets.

\Cref{tab:greedy-dp-results} shows the results of benchmarking the greedy DP algorithm against the selected problems.
As expected, the runtime of all sets (except the \emph{Auction} set) was improved significantly --- between \num{4} and \num{350} times --- with little or no increase in optimality gap.
The runtime improvements are most significant for the \gls{cfn} and \gls{mrf} problems, where the greedy DP variant is competitive with all three other solvers.

In situations where finding a solution quickly is more important than finding a guaranteed optimal solution, the greedy DP update is therefore a viable alternative.
There is no problem set where the optimality gap is significantly increased, and only three sets contain problems which could be solved by the standard algorithm but not using greedy DP updates.
Three problem sets from the max-\gls{csp} category additionally show improved optimality gaps as well as better runtimes.

\Cref{fig:cactus-greedy} illustrates the utility of the greedy DP update.
While it is slower for very small problems in the \emph{Black Hole} set, it is significantly faster in solving the more difficult problems.

% [todo] - theorize on reason of CFN/Auction not working!

With these results in mind, the greedy algorithm may be very useful when exact solutions aren't required.
% [todo] - mention fields where a "good enough" solution is satisfactory and why
This makes the algorithm with greedy updates extremely competitive in such cases.
The greedy update variant may also be useful as part of a broader strategy, by for instance providing fast and good upper bounds or by providing fast unproven solutions while waiting for exact solvers.
Another interesting direction for the greedy DP update could be to run it in parallel with the standard algorithm (sharing the immutable constraint components in memory), again providing quick approximative solutions as well as good solutions.

% Note: for some problems, including CFN/ProteinDesign, no loss in accuracy but great decrease in time - discuss this!

% Good as part of a broader strategy, to quickly obtain upper bounds?

% Interesting cactus plots: MaxCSP/BlackHole, MaxCSP/QCP, MRF/DBN

\begin{table}
	\centering
	% Updated 2014-05-24
	\caption{
		Optimality gap and runtime using the greedy DP update (setting \(\alpha=1\)).
		For several chosen problem sets, the greedy DP runtime is compared to the results obtained by the standard algorithm (see \cref{tab:comparative-results}).
		Problem sets marked with \textdagger{} include unsolved problems (no feasible solution found by the greedy DP update), and n/a values indicate that none of the problems in the set were solved.
		Runtimes based on less than \SI{70}{\percent} of the problems are faded.
	}
	\label{tab:greedy-dp-results}
	\begin{figcenter}
	\begin{tabular}{xySSS[round-mode=places,round-precision=3,scientific-notation=fixed,fixed-exponent=0]
				     S[round-mode=places,round-precision=3,scientific-notation=fixed,fixed-exponent=0]
				     S[round-mode=places,round-precision=2,scientific-notation=fixed,fixed-exponent=0]
				     S[round-mode=places,round-precision=2,scientific-notation=fixed,fixed-exponent=0]}
		\toprule
			{} & {} & \multicolumn{2}{c}{\(\#\) solved} & \multicolumn{2}{c}{Gap (\si{\percent})} & \multicolumn{2}{c}{Mean time (\si{\second})} \\
			\cmidrule(rl){3-4} \cmidrule(rl){5-6} \cmidrule(rl){7-8}
			{\normalsize Category} & {\normalsize Set} & {Std.} & {\(\alpha=1\)} & {Std.} & {\(\alpha=1\)} & {Std.} & {\(\alpha=1\)} \\
		\midrule
\acrshort{cfn}	&	Auction\textdagger	&	102	&	0	&	0.000000e+00	&	{\textcolor{gray}{n/a}}	&	82.8575	&	{\textcolor{gray}{n/a}} \\
%				&	CELAR\textdagger	&	10	&	4	&	9.081260e-07	&	0.00000000	&	\color{gray}193.3445	&	\color{gray}3.8775 \\
				&	ProteinDesign\textdagger	&	10	&	9	&	0.000000e+00	&	0.00000000	&	43.3995	&	0.7220 \\
				&	Warehouse\textdagger	&	38	&	53	&	0.000000e+00	&	0.00000000	&	\color{gray}55.8550	&	0.6780 \\
\acrshort{cp}	&	ParityLearning	&	7	&	7	&	1.800000e-05	&	0.000013	&	34.5300	&	3.1260 \\
\acrshort{cvpr}	&	Matching	&	4	&	4	&	0.000000e+00	&	0.00000000	&	17.9275	&	4.5525 \\
Max-\acrshort{csp}	&	BlackHole\textdagger	&	37	&	36	&	9.009009e-01	&	1.081081	&	58.8900	&	13.1665 \\
				&	Coloring	&	22	&	22	&	0.000000e+00	&	0.000000	&	1.6860	&	0.2080 \\
				&	Composed	&	80	&	80	&	1.342282e-01	&	0.00000000	&	20.3400	&	0.9980 \\
				&	Geometric	&	100	&	100	&	1.082434e-00	&	0.94082100	&	98.9760	&	13.3705 \\
				&	Langford	&	4	&	4	&	1.311265e-00	&	0.96711800	&	70.7775	&	7.3910 \\
				&	QCP	&	60	&	60	&	1.292034e-00	&	2.12260500	&	43.2575	&	4.4240 \\
\acrshort{mrf}	&	DBN	&	108	&	108	&	0.000000e+00	&	0.00000000	&	37.9040	&	0.4465 \\
%				&	Linkage\textdagger	&	8	&	10	&	0.000000e+00	&	0.00000000	&	\color{gray}41.0700	&	\color{gray}3.6005 \\
				&	ObjectDetection	&	37	&	37	&	6.465565e-00	&	6.46556500	&		279.8620	&	0.8380 \\
				&	Segmentation	&	100	&	100	&	0.000000e+00	&	0.000000	&	0.0310	&	0.1295 \\
		\bottomrule
	\end{tabular}
	\end{figcenter}
\end{table}

\begin{figure}[tp]
	\begin{figcenter}
	\input{figs/khappa1-cactus-MaxCSP-BlackHole.tikz}
	\end{figcenter}
	\caption{Accumulated runtime of the standard and greedy algorithm in the \emph{Black Hole} set, sorted by runtime individually for each variant. Note the logarithmic scale of the \(y\) axis.}
	\label{fig:cactus-greedy}
\end{figure}
