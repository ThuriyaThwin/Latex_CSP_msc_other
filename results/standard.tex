\section{Standard algorithm}
Benchmarking the standard algorithm on the large set of problems provided earlier produced mixed results.
The number of problems (out of the total number available from each set) that were solved by the in-the-middle algorithm indicate that the algorithm is able to solve the same types of problem as the \emph{Toulbar} and \emph{CPLEX} solvers, with a few exceptions.
This implies that the algorithm may be useful in most of the fields from which problems were drawn, but does not indicate whether it is useful in its current state, performance-wise.

However, as \cref{tab:comparative-results} shows, the algorithm performed very well when comparing runtime to other solvers and in fact it was the fastest for almost half of the sets after removing incomplete data (runtimes based on data where less than \SI{70}{\percent} of the problems were solved).
In most problem sets, the optimality gap was small as well --- for several sets optimal solutions were found --- with the notable exception of the \emph{Scene Decomposition} set\footnote{Note however that the Toulbar2 solver finds the same non-optimal solutions in this problem set.}.

It should be noted that Toulbar2, CPLEX and MaxHS may be at a slight disadvantage in terms of runtime presented in \cref{tab:comparative-results}.
Brief testing of the Toulbar2 solver indicated that the difference in hardware between the in-the-middle runtimes and those provided by \textcite{deGivry14} may skew the results in favour of the in-the-middle solver, with actual runtimes on the same hardware being \SIrange{0}{50}{\percent} lower for Toulbar2.
Fortunately, this difference only makes comparisons in a small number of the sets (\emph{Pedigree}, \emph{In-Painting} and \emph{Max-Clique}) potentially invalid, since the difference in runtime between solvers is large in most cases.

\begin{table}
	\centering
	% Updated 2014-05-25
	\caption{
		Optimality gap and runtime.
		For each problem instance used in the benchmark, the in-the-middle solver runtime is compared the other solvers included in the benchmark, and the objective value is compared to the best known optimum from \textcite{deGivry14}.
		Problem sets marked with \textdagger{} include unsolved problems (no feasible solution found by the in-the-middle solver), and n/a values indicate that none of the problems in the set were solved.
		Runtimes based on less than \SI{70}{\percent} of the problems are faded, while the best runtime of those remaining is emphasised.
	}
	\label{tab:comparative-results}
	\begin{figcenter}
	\begin{tabular}{xyHS[round-mode=places,round-precision=3,scientific-notation=fixed,fixed-exponent=0]
				    S[round-mode=places,round-precision=2,scientific-notation=fixed,fixed-exponent=0]
				    H%S[round-mode=places,round-precision=2,scientific-notation=fixed,fixed-exponent=0]
				    S[round-mode=places,round-precision=2,scientific-notation=fixed,fixed-exponent=0]
				    S[round-mode=places,round-precision=2,scientific-notation=fixed,fixed-exponent=0]
				    S[round-mode=places,round-precision=2,scientific-notation=fixed,fixed-exponent=0]}
		\toprule
			{} & {} & {} & {} & \multicolumn{5}{c}{Mean solution time (\si{\second})} \\
			\cmidrule(rl){5-9}
			{\normalsize Category} & {\normalsize Set} & {\(\#\) solved} & {Gap (\si{\percent})} & {ITM} & {MPLP2} & {Toulbar2} & {CPLEX} & {MaxHS} \\
		\midrule
\acrshort{cfn}	&	Auction\textdagger	&	{102/170}	&	0.000000e+00	&	\color{gray}82.8575	&	1200.00	&	8.195	&	\emshape 0.030	&	0.040 \\
				&	CELAR\textdagger	&	{10/16}	&	9.081260e-07	&	\color{gray}193.3445	&	1200.00	&	\emshape 22.375	&	1200.00	&	{\textcolor{gray}{n/a}} \\
				&	Pedigree	&	\emph{10/10}	&	1.804874e-00	&	\emshape 2.3750	&	{\textcolor{gray}{n/a}}	&	4.130	&	\color{gray}0.710	&	\color{gray}0.030 \\
				&	ProteinDesign	&	\emph{10/10}	&	0.000000e+00	&	43.3995	&	60.500	&	\emshape 2.330	&	1200.00	&	{\textcolor{gray}{n/a}} \\
				&	SPOT5\textdagger	&	{5/20}	&	4.977105e-03	&	\color{gray}6.4360	&	1200.00	&	1200.00	&	\emshape 0.465	&	\color{gray}0.820 \\
				&	Warehouse\textdagger	&	{38/55}	&	0.000000e+00	&	\color{gray}55.8550	&	57.970	&	0.160	&	\emshape 0.050	&	0.560 \\
%\acrshort{cp}	&	AMaze\textdagger	&	{0/6}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	544.545	&	{\textcolor{gray}{n/a}}	&	2.940 \\
%				&	FastFood\textdagger	&	{1/6}	&	0.000000e+00	&	0.0000	&	{\textcolor{gray}{n/a}}	&	0.0	&	0.010	&	0.0 \\
%\acrshort{cp}	&	Golomb\textdagger	&	{0/6}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	19.860	&	{\textcolor{gray}{n/a}}	&	42.670 \\
\acrshort{cp}	&	OnCallRostering\textdagger	&	{3/5}	&	4.000000e-06	&	\emshape 10.3540	&	{\textcolor{gray}{n/a}}	&	71.040	&	1200.0	&	18.950 \\
				&	ParityLearning	&	\emph{7/7}	&	1.800000e-05	&	\emshape 34.5300	&	{\textcolor{gray}{n/a}}	&	368.080	&	1200.0	&	\color{gray}222.690 \\
%				&	VRP\textdagger	&	{0/5}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	1200.0	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}} \\
%\acrshort{cvpr}	&	ChineseChars\textdagger	&	{0/100}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	1200.00	&	1200.0	&	1200.0	&	{\textcolor{gray}{n/a}} \\
%				&	ColorSeg\textdagger	&	{0/21}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	1200.00	&	1200.0	&	1200.0	&	{\textcolor{gray}{n/a}} \\
\acrshort{cvpr}	&	GeomSurf	&	\emph{600/600}	&	2.091307e-00	&	\emshape 0.0460	&	1.740	&	0.070	&	6.620	&	\color{gray}27.110 \\
				&	InPainting	&	\emph{4/4}	&	1.797097e-02	&	\emshape 1009.5145	&	1057.860	&	1200.0	&	1200.0	&	{\textcolor{gray}{n/a}} \\
				&	Matching	&	\emph{4/4}	&	0.000000e+00	&	17.9275	&	12.710	&	\emshape 4.120	&	1200.0	&	{\textcolor{gray}{n/a}} \\
%				&	MatchingStereo\textdagger	&	{0/2}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	1200.00	&	1200.0	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}} \\
				&	ObjectSeg	&	\emph{5/5}	&	3.253700e-04	&	\emshape 1200.0	&	\emshape 1200.00	&	\emshape 1200.0	&	\emshape 1200.0	&	{\textcolor{gray}{n/a}} \\
%				&	PhotoMontage\textdagger	&	{0/2}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}} \\
				&	SceneDecomp	&	\emph{715/715}	&	7.545481e+01	&	0.0210	&	0.110	&	\emshape 0.020	&	1200.0	&	\color{gray}521.160 \\
Max-\acrshort{csp}	&	BlackHole	&	\emph{37/37}	&	9.009009e-01	&	\emshape 58.8900	&	{\textcolor{gray}{n/a}}	&	1200.0	&	315.050	&	\color{gray}0.635 \\
				&	Coloring	&	\emph{22/22}	&	0.000000e+00	&	1.6860	&	{\textcolor{gray}{n/a}}	&	\emshape 0.405	&	1.275	&	\color{gray}0.030 \\
				&	Composed	&	\emph{80/80}	&	1.342282e-01	&	20.3400	&	1200.00	&	\emshape 0.115	&	5.755	&	32.690 \\
				&	EHI	&	{200/200}	&	9.000000e-01	&	\emshape 191.2190	&	{\textcolor{gray}{n/a}}	&	1200.0	&	1200.0	&	{\textcolor{gray}{n/a}} \\
				&	Geometric	&	\emph{100/100}	&	1.082434e-00	&	98.9760	&	{\textcolor{gray}{n/a}}	&	0.620	&	1200.0	&	\emshape 0.150 \\
				&	Langford	&	\emph{4/4}	&	1.311265e-00	&	\emshape 70.7775	&	1200.00	&	600.255	&	851.605	&	\color{gray}0.270 \\
				&	QCP	&	\emph{60/60}	&	1.292034e-00	&	43.2575	&	1200.00	&	1200.0	&	1200.0	&	\emshape 0.125 \\
\acrshort{mrf}	&	DBN	&	\emph{108/108}	&	0.000000e+00	&	37.9040	&	1200.00	&	\emshape 0.180	&	48.280	&	\color{gray}20.020 \\
				&	Grid\textdagger	&	{0/21}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	1200.00	&	1200.0	&	\emshape 160.640	&	\color{gray}542.850 \\
				&	ImageAlignment	&	\emph{10/10}	&	0.000000e+00	&	\emshape 0.5815	&	4.855	&	1.800	&	1200.0	&	{\textcolor{gray}{n/a}} \\
				&	Linkage\textdagger	&	{8/22}	&	0.000000e+00	&	\color{gray}41.0700	&	1200.00	&	32.050	&	327.625	&	\emshape 16.520 \\
				&	ObjectDetection	&	\emph{37/37}	&	6.465565e-00	&	\emshape 279.8620	&	1200.00	&	1200.0	&	1200.0	&	{\textcolor{gray}{n/a}} \\
				&	ProteinFolding\textdagger	&	{20/21}	&	0.000000e+00	&	1200.0000	&	1200.00	&	\emshape 23.140	&	\color{gray}116.735	&	{\textcolor{gray}{n/a}} \\
				&	Segmentation	&	\emph{100/100}	&	0.000000e+00	&	\emshape 0.0310	&	0.355	&	0.150	&	600.070	&	\color{gray}0.300 \\
%\acrshort{wpms}	&	Haplotyping	&	{0/100}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	1200.0	&	1200.0	&	5.200 \\
\acrshort{wpms}	&	MaxClique\textdagger	&	{46/62}	&	2.583333e-00	&	\emshape 257.0920	&	1200.00	&	389.745	&	481.550	&	\color{gray}8.795 \\
%				&	MIPLib\textdagger	&	{0/12}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	193.990	&	533.220	&	0.360 \\
%				&	PackupWeighted\textdagger	&	{0/99}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	292.960	&	0.280	&	4.620 \\
%				&	PlanningWithPref	&	{0/29}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	1200.0	&	1200.0	&	1.270 \\
%				&	TimeTabling	&	{0/25}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	1200.0	&	1200.0	&	83.800 \\
%				&	Upgradeability\textdagger	&	{0/100}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	{\textcolor{gray}{n/a}}	&	3.095	&	1.010	&	24.985 \\
		\bottomrule
	\end{tabular}
	\end{figcenter}
\end{table}

The algorithm shows promise especially in the Max-\gls{csp} and \gls{mrf} categories, where overall solution quality is good and the algorithm had the best performance for several sets.
Compared to both Toulbar2 and CPLEX, the in-the-middle algorithm appears to be a useful complement providing (good) approximative solutions to problems the other solvers have great difficulty in solving.
Results from the \gls{cp} category are also promising, but these problem sets are small and not all \gls{cp} problems have max-sum formulations.

\Cref{fig:cactus-std} shows accumulated runtimes for three of the sets in which the algorithm performed well.
The algorithm has a consistent advantage in the \emph{Segmentation} set (\cref{fig:cactus-std:segmentation}), which is reflected by the mean runtime in \cref{tab:comparative-results}.
\Cref{fig:cactus-std:dbn} highlights a more interesting situation.
It shows performance in the \emph{DBN} set, in which the algorithm has an advantage in total runtime across the whole set, almost entirely due to good performance on the more difficult problems.
In fact, the runtimes are fairly evenly distributed whereas the runtimes for CPLEX and Toulbar vary significantly between the difficult and easy problems of the set.
% [todo] - justify choice of median for the values (goes in method?)

\begin{figure}[tp]
	\begin{figcenter}
	\subfloat[The \emph{Segmentation} set of the \gls{mrf} category.\label{fig:cactus-std:segmentation}]{\input{figs/cactus-MRF-Segmentation.tikz}}
	\end{figcenter}
	\\
	\begin{figcenter}
	\subfloat[The \emph{DBN} set of the \gls{mrf} category.\label{fig:cactus-std:dbn}]{\input{figs/cactus-MRF-DBN.tikz}}
	\end{figcenter}
	\caption{Accumulated runtime of the algorithms in three different sets, sorted by runtime individually for every solver. Note the logarithmic scale of the \(y\) axis.}
	\label{fig:cactus-std}
\end{figure}

% [todo] - explain SceneDecomp anomaly? Maybe deGivry14 has something on it?

The largest problem solved optimally by the in-the-middle algorithm was an instance of in the \emph{In-Painting} set with search space \(d^n = 4^{\num{14400}}\).
The smallest unsolved instances are in the \emph{Auction} set, with seach spaces \(d^n \approx 2^{80}\).

% \begin{table}
% 	\centering
% 	% Updated 2014-05-25
% 	\caption{
% 		Solved problems.
% 		For each problem instance used in the benchmark, the number of problems solved by each solver is listed.
% 		%Some problem sets have been omitted.
% 	}
% 	% [review] - should this be in an appendix?
% 	\label{tab:number-solved}
% 	\begin{figcenter}
% 	\begin{tabular}{xyccHccc}
% 		\toprule
% 			{} & {} & {} & \multicolumn{5}{c}{\(\#\) solved} \\
% 			\cmidrule(rl){4-8}
% 			{\normalsize Category} & {\normalsize Set} & {\(\#\) of problems} & {ITM} & {MPLP2} & {Toulbar2} & {CPLEX} & {MaxHS} \\
% 		\midrule
% \acrshort{cfn}	&	Auction	&	170	&	102	&	97	&	170	&	170	&	170 \\
% 				&	CELAR	&	16	&	10	&	16	&	16	&	16	&	0 \\
% 				&	Pedigree	&	10	&	10	&	0	&	10	&	5	&	5 \\
% 				&	ProteinDesign	&	10	&	10	&	9	&	10	&	10	&	0 \\
% 				&	SPOT5	&	20	&	5	&	1	&	20	&	20	&	5 \\
% 				&	Warehouse	&	55	&	38	&	54	&	55	&	55	&	47 \\
% %\acrshort{cp}	&	AMaze	&	6	&	0	&	0	&	2	&	0	&	6 \\
% %				&	FastFood	&	6	&	1	&	0	&	1	&	1	&	1 \\
% %\acrshort{cp}	&	Golomb	&	6	&	0	&	0	&	3	&	0	&	3 \\
% \acrshort{cp}	&	OnCallRostering	&	5	&	3	&	0	&	3	&	3	&	3 \\
% 				&	ParityLearning	&	7	&	7	&	0	&	7	&	7	&	3 \\
% %				&	VRP	&	5	&	0	&	0	&	5	&	0	&	0 \\
% %\acrshort{cvpr}	&	ChineseChars	&	100	&	0	&	100	&	100	&	100	&	0 \\
% %				&	ColorSeg	&	21	&	0	&	16	&	21	&	5	&	0 \\
% \acrshort{cvpr}	&	GeomSurf	&	600	&	600	&	324	&	600	&	600	&	310 \\
% 				&	InPainting	&	4	&	4	&	4	&	4	&	3	&	0 \\
% 				&	Matching	&	4	&	4	&	1	&	4	&	4	&	0 \\
% %				&	MatchingStereo	&	2	&	0	&	2	&	2	&	0	&	0 \\
% 				&	ObjectSeg	&	5	&	5	&	5	&	5	&	4	&	0 \\
% %				&	PhotoMontage	&	2	&	0	&	0	&	0	&	0	&	0 \\
% 				&	SceneDecomp	&	715	&	715	&	715	&	715	&	715	&	1 \\
% Max-\acrshort{csp}	&	BlackHole	&	37	&	37	&	0	&	37	&	37	&	10 \\
% 				&	Coloring	&	22	&	22	&	0	&	20	&	22	&	12 \\
% 				&	Composed	&	80	&	80	&	80	&	80	&	80	&	80 \\
% 				&	EHI	&	200	&	200	&	0	&	200	&	200	&	0 \\
% 				&	Geometric	&	100	&	100	&	0	&	100	&	100	&	88 \\
% 				&	Langford	&	4	&	4	&	1	&	4	&	4	&	2 \\
% 				&	QCP	&	60	&	60	&	4	&	60	&	60	&	46 \\
% \acrshort{mrf}	&	DBN	&	108	&	108	&	108	&	108	&	108	&	30 \\
% 				&	Grid	&	21	&	0	&	21	&	21	&	21	&	4 \\
% 				&	ImageAlignment	&	10	&	10	&	10	&	10	&	8	&	0 \\
% 				&	Linkage	&	22	&	8	&	5	&	22	&	22	&	20 \\
% 				&	ObjectDetection	&	37	&	37	&	23	&	37	&	37	&	0 \\
% 				&	ProteinFolding	&	21	&	20	&	21	&	21	&	10	&	0 \\
% 				&	Segmentation	&	100	&	100	&	100	&	100	&	100	&	50 \\
% %\acrshort{wpms}	&	Haplotyping	&	100	&	0	&	0	&	100	&	96	&	25 \\
% \acrshort{wpms}	&	MaxClique	&	62	&	46	&	56	&	62	&	62	&	36 \\
% %				&	MIPLib	&	12	&	0	&	0	&	5	&	5	&	3 \\
% %				&	PackupWeighted	&	99	&	0	&	0	&	98	&	99	&	85 \\
% %				&	PlanningWithPref	&	29	&	0	&	0	&	24	&	21	&	27 \\
% %				&	TimeTabling	&	25	&	0	&	0	&	1	&	1	&	1 \\
% %				&	Upgradeability	&	100	&	0	&	0	&	100	&	100	&	100 \\
% 		\bottomrule
% 	\end{tabular}
% 	\end{figcenter}
% \end{table}
